{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Set visual style for plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA RESCUE: Fix Corrupted CSV Headers\n",
    "# ==========================================\n",
    "# This part removes Git markers (<<<<, ====, >>>>) from the CSV file itself\n",
    "input_file = 'dirty_cafe_sales.csv'\n",
    "fixed_file = 'dirty_cafe_sales_fixed.csv'\n",
    "\n",
    "try:\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Filter out lines created by Git merge conflicts\n",
    "    clean_lines = [\n",
    "        line for line in lines \n",
    "        if not (line.startswith('<<<<<<<') or \n",
    "                line.startswith('=======') or \n",
    "                line.startswith('>>>>>>>'))\n",
    "    ]\n",
    "\n",
    "    with open(fixed_file, 'w') as f:\n",
    "        f.writelines(clean_lines)\n",
    "    print(f\"Successfully cleaned Git markers. Working with: {fixed_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {input_file} not found. Please ensure the file is in the same folder.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD AND CLEAN DATA\n",
    "# ==========================================\n",
    "# Load the rescued dataset\n",
    "df = pd.read_csv(fixed_file)\n",
    "\n",
    "# Strip any leading/trailing whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Replace invalid entries with NaN\n",
    "invalid_values = ['ERROR', 'UNKNOWN', '']\n",
    "df_cleaned.replace(invalid_values, np.nan, inplace=True)\n",
    "\n",
    "# Convert data types\n",
    "numerical_cols = ['Quantity', 'Price Per Unit', 'Total Spent']\n",
    "for col in numerical_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "\n",
    "# Convert Transaction Date to datetime\n",
    "if 'Transaction Date' in df_cleaned.columns:\n",
    "    df_cleaned['Transaction Date'] = pd.to_datetime(df_cleaned['Transaction Date'], errors='coerce')\n",
    "\n",
    "# Recalculate Total Spent where missing but Quantity and Price exist\n",
    "valid_calc = df_cleaned['Quantity'].notna() & df_cleaned['Price Per Unit'].notna()\n",
    "df_cleaned.loc[df_cleaned['Total Spent'].isna() & valid_calc, 'Total Spent'] = \\\n",
    "    df_cleaned['Quantity'] * df_cleaned['Price Per Unit']\n",
    "\n",
    "# ==========================================\n",
    "# 3. IMPUTATION\n",
    "# ==========================================\n",
    "# Numerical Imputation (using Median)\n",
    "for col in numerical_cols:\n",
    "    if col in df_cleaned.columns and df_cleaned[col].isnull().any():\n",
    "        median_val = df_cleaned[col].median()\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(median_val)\n",
    "\n",
    "# Categorical Imputation (using Placeholder 'Missing')\n",
    "categorical_cols = ['Item', 'Payment Method', 'Location']\n",
    "for col in categorical_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = df_cleaned[col].fillna('Missing')\n",
    "\n",
    "# Date Imputation (using Mode)\n",
    "if 'Transaction Date' in df_cleaned.columns:\n",
    "    mode_date = df_cleaned['Transaction Date'].mode()[0]\n",
    "    df_cleaned['Transaction Date'] = df_cleaned['Transaction Date'].fillna(mode_date)\n",
    "\n",
    "# ==========================================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "# Extract time-based features\n",
    "if 'Transaction Date' in df_cleaned.columns:\n",
    "    df_cleaned['Transaction Month'] = df_cleaned['Transaction Date'].dt.month.astype(str)\n",
    "    df_cleaned['Transaction Day'] = df_cleaned['Transaction Date'].dt.day.astype(str)\n",
    "    df_cleaned['Transaction Weekday'] = df_cleaned['Transaction Date'].dt.day_name()\n",
    "\n",
    "# Drop columns that won't be used in the model\n",
    "cols_to_drop = ['Transaction ID', 'Transaction Date']\n",
    "df_modeling = df_cleaned.drop(columns=[c for c in cols_to_drop if c in df_cleaned.columns])\n",
    "\n",
    "# One-Hot Encoding for categorical variables\n",
    "categorical_features = ['Item', 'Payment Method', 'Location', 'Transaction Month', 'Transaction Day', 'Transaction Weekday']\n",
    "df_encoded = pd.get_dummies(df_modeling, columns=[c for c in categorical_features if c in df_modeling.columns], drop_first=False)\n",
    "\n",
    "# Convert boolean columns to integer (1/0)\n",
    "for col in df_encoded.columns:\n",
    "    if df_encoded[col].dtype == 'bool':\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "# ==========================================\n",
    "# 5. VISUALIZATIONS\n",
    "# ==========================================\n",
    "# --- A. Correlation Heatmap ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr = df_cleaned[['Quantity', 'Price Per Unit', 'Total Spent']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# --- B. Distribution of Total Spent ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_cleaned['Total Spent'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Total Spent')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df_cleaned['Total Spent'], color='lightgreen')\n",
    "plt.title('Box Plot of Total Spent')\n",
    "plt.show()\n",
    "\n",
    "# --- C. Mean Sales by Category ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "item_sales = df_cleaned.groupby('Item')['Total Spent'].mean().sort_values(ascending=False)\n",
    "payment_sales = df_cleaned.groupby('Payment Method')['Total Spent'].mean().sort_values(ascending=False)\n",
    "location_sales = df_cleaned.groupby('Location')['Total Spent'].mean().sort_values(ascending=False)\n",
    "\n",
    "item_sales.plot(kind='bar', ax=axes[0], color='lightcoral', title='Mean Sales by Item')\n",
    "payment_sales.plot(kind='bar', ax=axes[1], color='lightgreen', title='Mean Sales by Payment Method')\n",
    "location_sales.plot(kind='bar', ax=axes[2], color='gold', title='Mean Sales by Location')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 6. MODELING\n",
    "# ==========================================\n",
    "# Prepare features (X) and target (y)\n",
    "if 'Total Spent' in df_encoded.columns:\n",
    "    X = df_encoded.drop('Total Spent', axis=1)\n",
    "    y = df_encoded['Total Spent']\n",
    "\n",
    "    # 80/20 Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Linear Regression (Baseline) ---\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    print(f\"LR - RMSE: {mean_squared_error(y_test, y_pred_lr, squared=False):.4f}\")\n",
    "    print(f\"LR - MAE: {mean_absolute_error(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "    # --- Random Forest Regressor ---\n",
    "    rfr = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_pred_rfr = rfr.predict(X_test)\n",
    "    print(f\"\\nRFR - RMSE: {mean_squared_error(y_test, y_pred_rfr, squared=False):.4f}\")\n",
    "    print(f\"RFR - MAE: {mean_absolute_error(y_test, y_pred_rfr):.4f}\")\n",
    "\n",
    "# Save the final cleaned data\n",
    "df_cleaned.to_csv('cleaned_cafe_sales.csv', index=False)\n",
    "print(\"\\nFinal cleaned data saved as 'cleaned_cafe_sales.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
